{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3c2264-ad51-4d26-ad78-17f1a61148c7",
   "metadata": {},
   "source": [
    "### 一、unsloth快速使用入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a790496-d887-4d14-bf36-aeb2a4b0a944",
   "metadata": {},
   "source": [
    "#### 1.借助unsloth进行模型推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784f92ca7f08be8",
   "metadata": {},
   "source": [
    "#### 环境：jupyter内核：deepseekR1_cu126     虚拟环境：deepseekR1_cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595772fb6d4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"unsloth[cu126-torch260] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384b60a2175b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54fc52504f6f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global http.proxy http://127.0.0.1:7890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b7f3ad31c1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ee019e68d725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269629c851978b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de7d69df9a0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66984724555af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182517dae133baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ./triton-2.1.0-cp311-cp311-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f70fe5814e2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ./psutil-6.1.1-cp37-abi3-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1e42c8ea50ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m ipykernel install --user --name=your_env_name --display-name \"Python (deepseekR1_cu126_2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c4c0167a718f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab4f61a284ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # 如果输出是 True，说明 GPU 支持正确配置\n",
    "print(torch.cuda.current_device())  # 输出当前使用的设备\n",
    "print(torch.cuda.get_device_name(0))  # 输出 GPU 名称\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458dfa934949106",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ca40b43a74b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/woct0rdho/triton-windows/releases/download/v3.2.0-windows.post9/triton-3.2.0-cp311-cp311-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07574877c9a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4bcf877ad5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847f228-7910-43d6-91c6-515b9d9e2ef3",
   "metadata": {},
   "source": [
    "- 尝试用unsloth进行LLama模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667230ceeaf1b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37319bd-28b9-4c00-9c24-bd7ed75cd922",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先设置关键参数，并读取模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27de3b26800d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./QwQ-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dde18c5044da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model Qwen/QwQ-32B --local_dir ./QwQ-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e148d0c58d9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./DeepSeek-R1-Distill-Llama-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b14aeb91e99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./DeepSeek-R1-Distill-Qwen-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8641a1ee485dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model deepseek-ai/Deepseek-R1-Distill-Llama-70B --local_dir ./DeepSeek-R1-Distill-Llama-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031908f10383230",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --local_dir ./DeepSeek-R1-Distill-Qwen-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f5a2113d14d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model deepseek-ai/Deepseek-R1-Distill-Llama-8B --local_dir ./Deepseek-R1-Distill-Llama-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80cf31244c57fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./Deepseek-R1-Distill-Llama-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462b96a274911e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9112469ea515f59e",
   "metadata": {},
   "source": [
    "2846b8100e2b47cf0866f7c8e314e473d129bdd9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd26a2-92f4-477c-8db5-f330add5d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4608195-1e9d-47c6-8c50-e752da195fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 4096\n",
    "dtype = None \n",
    "load_in_4bit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b514fdec9e6c820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bc87f-731e-4ccc-8b75-2815a0ea1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"./DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e19d8-365d-4464-badb-1bc1d6ec77dd",
   "metadata": {},
   "source": [
    "此时model就是读取进来的DeepSeek R1 8B蒸馏模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687092f-94c7-450a-b251-fceb26e5a716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41d797-5505-415d-93f8-2e6adaf4f961",
   "metadata": {},
   "source": [
    "而tokenizer则是分词器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bac590-0f5b-4c71-98ea-320c00d69b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7998c2-3505-45e6-98bd-e913609b0530",
   "metadata": {},
   "source": [
    "将模型调整为推理模式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cad53-991e-4904-8c03-e06259020939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a80018-7759-44b1-9ec1-88c5a62a1e7c",
   "metadata": {},
   "source": [
    "然后即可和模型进行对话："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c1a9f-12a7-4144-afc3-3f0d7ab47fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"hello\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9cdc7-9f6e-466a-8a8d-b88ce06b69ec",
   "metadata": {},
   "source": [
    "然后这里我们首先需要借助分词器，将输入的问题转化为标记索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85aa14b-f4f2-45c8-90bd-238b875b16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([question], return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01d5b0-542b-4d58-9209-bf5f265a2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c2f92-5814-47a2-9c8f-244d828344b3",
   "metadata": {},
   "source": [
    "最后再带入inputs进行对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d68a5-56c3-478d-9c6b-63095fe38660",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ce6c0-871f-42dc-a6d6-ca694464580d",
   "metadata": {},
   "source": [
    "此时得到的回复也是词索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedeeac-5163-4a3a-b33e-038ed93bf1fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f33d9-ebbd-4ed9-bce5-14802d18ec67",
   "metadata": {},
   "source": [
    "同样需要分词器将其转化为文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a281f-cc79-4e79-b765-b12603f23040",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d7add-cfa5-4a5a-88bc-e1b498fd050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8005e-a3df-43b4-bf07-6d189457276f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f7d8b-ae44-4e9d-a386-5a9645456719",
   "metadata": {},
   "source": [
    "至此我们就完成了unsloth模型推理流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1ccf8-7fc1-4eb1-bbb2-cb75b645f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qwen, tokenizer_qwen = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"./DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead11f1-fe6d-4de7-abf1-daa30539b357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model_qwen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0518f-7b80-4ddf-a00f-d804da59cf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer_qwen([question], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model_qwen.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "response = tokenizer_qwen.batch_decode(outputs)\n",
    "\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea63eb8c-ace2-4287-b924-6d8783ad2c95",
   "metadata": {},
   "source": [
    "#### 2.带入问答模板进行回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10aee95-a38d-4e3b-9a81-3cf1050a1ecf",
   "metadata": {},
   "source": [
    "- 结构化输入方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b427d8-6931-406f-a2ab-38fdb38b613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style_chat = \"\"\"请写出一个恰当的回答来完成当前对话任务。\n",
    "\n",
    "### Instruction:\n",
    "你是一名助人为乐的助手。\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc959f-0190-4307-aa0b-43d26a81b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"你好，好久不见！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d63aa1-48da-4173-87f0-12a334596f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[prompt_style_chat.format(question, \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe11da-3433-4c80-8723-861cce6ee031",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([prompt_style_chat.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b4bf8-c61f-4276-bfed-86a28b34fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be62f68-2c81-4056-b678-948a5bc893f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7459285-9821-4828-a26f-9c9c70b42420",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee5204-8c35-4e63-9e19-2a33894a4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc39741-01df-4adb-88fb-885bc4340e2e",
   "metadata": {},
   "source": [
    "- 复杂问题测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89626c-b70a-42a5-8a91-c21c8b28cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"请证明根号2是无理数。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad1369-ccd4-4885-872a-686277148c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([prompt_style_chat.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a02c58-9c03-4e22-bb38-d5f8eb13d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a82fc-2e5e-48c4-9460-1bf9d1bd2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c862fa3-ffe2-4736-829d-8f201716dddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e5d96-c090-4d06-b133-c36b789e41b8",
   "metadata": {},
   "source": [
    "### 二、最小可行性实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672971b-0d59-4c5a-9461-fa7e4c8e1cb4",
   "metadata": {},
   "source": [
    "#### 1.数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d6b32-4b56-4184-80da-202d7dd589af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef1f84-74f4-4779-9326-a11502aa6ae1",
   "metadata": {},
   "source": [
    "- 下载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d4f6f-38ce-438e-be64-951f4b907fd7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来使用datasets进行数据集下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924a688-b61e-4d6d-bc2e-fa0b8c013ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4635bd-5d5d-406b-900d-eccbfaf261a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90685ac-6510-4fd4-9c2d-def17e0dc6d5",
   "metadata": {},
   "source": [
    "再次确认提示词模板："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef18a3-d669-4acf-8da7-4da22b3aaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request. \n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You are a hydrogen storage big data artificial intelligence.\n",
    "Please answer the following question. \n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53db946-57c9-40c0-aded-1ac2462f12ec",
   "metadata": {},
   "source": [
    "然后提取并设置文本生成结束的标记："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803474abeedf56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token = \"</s>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c75cc9-61f4-4ff3-9124-34ff78456a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee28cc-1fe8-4c79-860b-c7792b269530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"input\"]\n",
    "    cots = examples[\"chain_of_thought\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f68e319425ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 修改为你的代理地址（例如 Clash/V2rayN/SSTap 等工具提供的本地代理端口）\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Yy245/cot_2000\", split=\"train\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85106a25-688e-447f-b411-11cc1b0206df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca9256-067a-4f7b-a339-e0473bc4a81e",
   "metadata": {},
   "source": [
    "然后进行结构化处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c249c5-ec25-448d-8045-46042d9ad963",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc62f8-96f2-4905-b0e6-c28a60954ce7",
   "metadata": {},
   "source": [
    "将数据集整理为如下形式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34f952-656e-44d6-a778-8a70690d4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478885f-5a4b-431c-b705-6faea5bcf087",
   "metadata": {},
   "source": [
    "- 数据集保存地址"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ca9f9-34ed-45d8-be58-b4ed829dbcbf",
   "metadata": {},
   "source": [
    "默认情况下数据集保存在主目录下.cache文件夹中，数据文件格式如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a4418-2f7b-4b3e-9efa-efa2a5fd6dd7",
   "metadata": {},
   "source": [
    "#### 2.开启微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7956b-039b-483f-9b50-15caf056dfb9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后即可把模型设置为微调模式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f9bf9-c089-4546-af8e-9eb56ca31b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  \n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  \n",
    "    bias=\"none\",  \n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  \n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d5b06-50b4-4d78-a902-e2df87221f3f",
   "metadata": {},
   "source": [
    "然后导入相关的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d135473-1c60-4555-9a14-8abd5e5cabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba075b6a8192180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e168c5-df66-4a26-b65d-ad5251db7e76",
   "metadata": {},
   "source": [
    "创建有监督微调对象："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b0beb801f9ab7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06e808283bae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2月15日训练\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=1,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs = 5,\n",
    "\n",
    "        warmup_steps=5,\n",
    "        # max_steps=60,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1622f1-a0d9-495e-8162-8623027d4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:if you want to train integrated\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=1,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
    "        warmup_steps=5,\n",
    "        max_steps=60,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=5,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836f8b5-b608-4af2-be5c-c1a4d4de74c5",
   "metadata": {},
   "source": [
    "这段代码主要是用 **`SFTTrainer`** 进行 **监督微调（Supervised Fine-Tuning, SFT）**，适用于 `transformers` 和 `Unsloth` 生态中的模型微调：\n",
    "**1. 导入相关库**\n",
    "- **`SFTTrainer`**（来自 `trl` 库）：\n",
    "  - `trl`（Transformer Reinforcement Learning）是 Hugging Face 旗下的 `trl` 库，提供 **监督微调（SFT）** 和 **强化学习（RLHF）** 相关的功能。\n",
    "  - `SFTTrainer` 主要用于 **有监督微调（Supervised Fine-Tuning）**，适用于 `LoRA` 等低秩适配微调方式。\n",
    "\n",
    "- **`TrainingArguments`**（来自 `transformers` 库）：\n",
    "  - 这个类用于定义 **训练超参数**，比如批量大小、学习率、优化器、训练步数等。\n",
    "\n",
    "- **`is_bfloat16_supported()`**（来自 `unsloth`）：\n",
    "  - 这个函数检查 **当前 GPU 是否支持 `bfloat16`（BF16）**，如果支持，则返回 `True`，否则返回 `False`。\n",
    "  - `bfloat16` 是一种更高效的数值格式，在 **新款 NVIDIA A100/H100** 等 GPU 上表现更优。\n",
    "\n",
    "**2. 初始化 `SFTTrainer` 进行模型微调**\n",
    "\n",
    "##### **参数解析**\n",
    "##### **① `SFTTrainer` 部分**\n",
    "| 参数                              | 作用 |\n",
    "|---------------------------------|------|\n",
    "| `model=model`                   | 指定需要进行微调的 **预训练模型** |\n",
    "| `tokenizer=tokenizer`           | 指定 **分词器**，用于处理文本数据 |\n",
    "| `train_dataset=dataset`         | 传入 **训练数据集** |\n",
    "| `dataset_text_field=\"text\"`     | 指定数据集中哪一列包含 **训练文本**（在 `formatting_prompts_func` 里处理） |\n",
    "| `max_seq_length=max_seq_length` | **最大序列长度**，控制输入文本的最大 Token 数量 |\n",
    "| `dataset_num_proc=1`            | **数据加载的并行进程数**，提高数据预处理效率 |\n",
    "\n",
    "##### **② `TrainingArguments` 部分**\n",
    "| 参数 | 作用 |\n",
    "|------|------|\n",
    "| `per_device_train_batch_size=2` | 每个 **GPU/设备** 的训练批量大小（较小值适合大模型） |\n",
    "| `gradient_accumulation_steps=4` | **梯度累积步数**（相当于 `batch_size=2 × 4 = 8`） |\n",
    "| `warmup_steps=5` | **预热步数**（初始阶段学习率较低，然后逐步升高） |\n",
    "| `max_steps=60` | **最大训练步数**（控制训练的总步数，此处总共约消耗60*8=480条数据） |\n",
    "| `learning_rate=2e-4` | **学习率**（`2e-4` = 0.0002，控制权重更新幅度） |\n",
    "| `fp16=not is_bfloat16_supported()` | 如果 **GPU 不支持 `bfloat16`，则使用 `fp16`（16位浮点数）** |\n",
    "| `bf16=is_bfloat16_supported()` | 如果 **GPU 支持 `bfloat16`，则启用 `bfloat16`（训练更稳定）** |\n",
    "| `logging_steps=10` | **每 10 步记录一次训练日志** |\n",
    "| `optim=\"adamw_8bit\"` | **使用 `adamw_8bit`（8-bit AdamW优化器）减少显存占用** |\n",
    "| `weight_decay=0.01` | **权重衰减（L2 正则化）**，防止过拟合 |\n",
    "| `lr_scheduler_type=\"linear\"` | **学习率调度策略**（线性衰减） |\n",
    "| `seed=3407` | **随机种子**（保证实验结果可复现） |\n",
    "| `output_dir=\"outputs\"` | **训练结果的输出目录** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153cc26d-f6c9-4979-bb12-9c07849bcf06",
   "metadata": {},
   "source": [
    "然后设置wandb（可选）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a41b7-50bf-4f0f-8240-777b3c80f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda0b4a-d2ca-4b36-87ca-59d025ef7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=\"2846b8100e2b47cf0866f7c8e314e473d129bdd9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea7966-4da4-463e-b4c4-cf628b74f3d2",
   "metadata": {},
   "source": [
    "然后开始微调："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8a05c21dcf34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    inputs = batch[\"input_ids\"]\n",
    "    print(inputs.shape)  # 确保形状正确\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd782462-3d29-490c-9d63-4cb43a240883",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1278f09-4a99-4833-900a-659cd3e002eb",
   "metadata": {},
   "source": [
    "此时wandb中显示内容如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107a62e-eed6-49ad-8c65-7b51b12819ba",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250206200441907.png\" alt=\"image-20250206200441907\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05245a7d-6239-436d-847d-5d3188e1ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa75b2-0345-4c18-8eda-ebf1241b269b",
   "metadata": {},
   "source": [
    "注意，unsloth在微调结束后，会自动更新模型权重（在缓存中），因此无需手动合并模型权重即可直接调用微调后的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf4cf4-ef13-4e3f-bc7f-d08fd36ffc4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145f2f73aadabf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bca6ee-fc4c-4ca0-ab9d-d099f628f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([prompt_style.format(question_1, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb2f57-8e83-484f-b8b6-e34d9d9a529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46783905-93f7-4886-9920-2ca46d836593",
   "metadata": {},
   "source": [
    "测试第二个问题问答效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51202ad8c48812",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request. \n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You are a solid-state hydrogen storage big data artificial intelligence.\n",
    "Please answer the following question. \n",
    "\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f237deed3ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"What is the hydrogen storage data for component Ti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850a79-eba4-44fc-98d8-1488a85742a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([prompt_style.format(question_1, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1834b90-c3e2-4a0b-b967-0293726a78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83871526-b408-4090-8ea5-73ed0a7daba7",
   "metadata": {},
   "source": [
    "#### 3.模型合并"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b846d-ebe6-4b9a-a5ff-e5971258e3fc",
   "metadata": {},
   "source": [
    "此时本地保存的模型权重在`outputs`文件夹中："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378c031-80f1-4eac-9775-7557188981ab",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250206195427494.png\" alt=\"image-20250206195427494\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e9f53-0ee6-4830-86b9-4ba2f04c5169",
   "metadata": {},
   "source": [
    "然后可使用如下代码进行模型权重合并："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15877f4c-e0c4-4ef0-ba89-70381b2d1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_local = \"qing_gpt_100_tips_5_epoch\"\n",
    "model.save_pretrained(new_model_local) \n",
    "tokenizer.save_pretrained(new_model_local)\n",
    "\n",
    "model.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac9133-227e-477e-9e0e-1b26c2c87480",
   "metadata": {},
   "source": [
    "保存结束后，即可在当前文件夹中看到对应模型："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62c52e-387b-4673-b214-ab3e060a76fb",
   "metadata": {},
   "source": [
    "然后即可将其推送到huggingface上并保存为GGUF格式文件并进行调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ae17170482765",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd D:\\llama.cpp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cacdec58dd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python convert_lora_to_gguf.py DeepSeek-R1-Medical-COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e85dd-7926-4716-a046-ac07ca67d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained_gguf(\"./model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "# model.save_pretrained_gguf(\"dir\", tokenizer, quantization_method = \"q8_0\")\n",
    "model.save_pretrained_gguf(\"./model\", tokenizer, quantization_method = \"f16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7bc26-8d7a-4388-aa4b-4c48b6875f21",
   "metadata": {},
   "source": [
    "### 三、完整高效微调实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446a0c5-c8cf-45ae-a069-8a4ee40f9e60",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们尝试带入全部数据进行高效微调，以提升模型微调效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d9b24-29e0-4868-afb4-527ae245d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Yy245/qing_chat\",\"en\", split = \"train\",trust_remote_code=True)\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb8209-4f35-4551-8a8b-35aecb0eccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  \n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  \n",
    "    bias=\"none\",  \n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  \n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7dce0-84cd-46e2-b0a7-a05e3b81b211",
   "metadata": {},
   "source": [
    "这里设置epoch为3，遍历3次数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739bb1a-0d51-48d2-beb3-0d6449e7ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=1,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs = 1,\n",
    "        warmup_steps=5,\n",
    "        # max_steps=60,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8576d5-8fb1-4b5d-8707-24703ff79945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87f0b5-c6cc-4885-b19d-bc3b3cd1cfae",
   "metadata": {},
   "source": [
    "这里总共训练约15个小时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff611dd-e6be-4066-97d4-b288711465bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b0182-51de-4e71-a15a-003d56c1da7f",
   "metadata": {},
   "source": [
    "最后进行模型权重保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099775b8-7ff0-4dee-b422-a72bc1d5a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_local = \"DeepSeek-R1-Medical-COT—1-epoch\"\n",
    "model.save_pretrained(new_model_local) \n",
    "tokenizer.save_pretrained(new_model_local)\n",
    "\n",
    "model.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
